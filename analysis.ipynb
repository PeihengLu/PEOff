{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of editing efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### PRIDICT\n",
    "\n",
    "The dataset of pridict-1 has 90k examples, the example suggests using a zero inflated poisson or gaussian distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Load the data\u001b[39;00m\n\u001b[1;32m      9\u001b[0m path \u001b[38;5;241m=\u001b[39m pjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpridict-90k.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m efficiency_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maverageedited\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     13\u001b[0m df \u001b[38;5;241m=\u001b[39m df[df[efficiency_col]\u001b[38;5;241m.\u001b[39mnotnull()]\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1024\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1011\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1012\u001b[0m     dialect,\n\u001b[1;32m   1013\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1021\u001b[0m )\n\u001b[1;32m   1022\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.11/site-packages/pandas/io/parsers/readers.py:624\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1921\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1914\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1916\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1917\u001b[0m     (\n\u001b[1;32m   1918\u001b[0m         index,\n\u001b[1;32m   1919\u001b[0m         columns,\n\u001b[1;32m   1920\u001b[0m         col_dict,\n\u001b[0;32m-> 1921\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1923\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1925\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:921\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:1083\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:1456\u001b[0m, in \u001b[0;36mpandas._libs.parsers._maybe_upcast\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.11/site-packages/numpy/core/multiarray.py:1131\u001b[0m, in \u001b[0;36mputmask\u001b[0;34m(a, mask, values)\u001b[0m\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m \u001b[38;5;124;03m    copyto(dst, src, casting='same_kind', where=True)\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \n\u001b[1;32m   1127\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (dst, src, where)\n\u001b[0;32m-> 1131\u001b[0m \u001b[38;5;129m@array_function_from_c_func_and_dispatcher\u001b[39m(_multiarray_umath\u001b[38;5;241m.\u001b[39mputmask)\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mputmask\u001b[39m(a, \u001b[38;5;241m/\u001b[39m, mask, values):\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;124;03m    putmask(a, mask, values)\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1171\u001b[0m \n\u001b[1;32m   1172\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, mask, values)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from os.path import join as pjoin\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the data\n",
    "path = pjoin('data', 'pridict-90k.csv')\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "efficiency_col = 'averageedited'\n",
    "df = df[df[efficiency_col].notnull()]\n",
    "\n",
    "\n",
    "# list out zero efficiency as a separate group\n",
    "zero_efficiency = df[df[efficiency_col] == 0]\n",
    "non_zero_efficiency = df[df[efficiency_col] > 0]\n",
    "\n",
    "# plot the distribution of efficiency\n",
    "fig, ax = plt.subplots()\n",
    "sns.histplot(non_zero_efficiency[efficiency_col], bins=20, ax=ax)\n",
    "ax.set_xlabel('Efficiency')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Efficiency Distribution')\n",
    "\n",
    "# true zero is a separate bar\n",
    "ax.bar(0, len(zero_efficiency), color='red', alpha=0.5, width=2)\n",
    "\n",
    "\n",
    "# save the figure\n",
    "fig.savefig(pjoin('figures', 'efficiency_distribution.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# acquire a subset of the pridict 90k dataset\n",
    "from os.path import join as pjoin\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the data\n",
    "path = pjoin('data', 'pridict-90k.csv')\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "efficiency_col = 'averageedited'\n",
    "df = df[df[efficiency_col].notnull()]\n",
    "\n",
    "# rename name column to HGVS\n",
    "df.rename(columns={'Name': 'HGVS'}, inplace=True)\n",
    "\n",
    "# get 1000 random samples and save a pridict-90k-small.csv\n",
    "df.sample(30).to_csv(pjoin('data', 'pridict-90k-small.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HGVS to hg38 coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:07<00:00,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   averageedited  averageunedited  averageindel  \\\n",
      "0      61.037202        15.624968     23.337831   \n",
      "1      75.728608        21.184532      3.086859   \n",
      "2      62.291955        14.233247     23.474798   \n",
      "3      73.368779        12.469879     14.161342   \n",
      "4       2.869652        92.088859      5.041489   \n",
      "\n",
      "                                              HGVS   Gene  \\\n",
      "0           NM_000157.4(GBA):c.630del (p.Val211fs)    GBA   \n",
      "1           NM_178152.3(DCX):c.266G>C (p.Arg89Pro)    DCX   \n",
      "2        NM_000527.4(LDLR):c.1786A>T (p.Lys596Ter)   LDLR   \n",
      "3       NM_000135.4(FANCA):c.3558dup (p.Arg1187fs)  FANCA   \n",
      "4  NM_006920.6(SCN1A):c.3769_3779del (p.Leu1257fs)  SCN1A   \n",
      "\n",
      "                                           Phenotype  PBSlength  \\\n",
      "0                                    Gaucher disease         13   \n",
      "1                                        Heterotopia         13   \n",
      "2                      Familial hypercholesterolemia         13   \n",
      "3  Fanconi anemia;Fanconi anemia, complementation...         13   \n",
      "4               Severe myoclonic epilepsy in infancy         13   \n",
      "\n",
      "   RToverhanglength  RTlength ReferenceAllele  ... protobase_19  \\\n",
      "0                 7        12               G  ...            A   \n",
      "1                15        20               C  ...            A   \n",
      "2                15        22               A  ...            C   \n",
      "3                10        19               -  ...            G   \n",
      "4                15        30     CATTTTAGAAG  ...            T   \n",
      "\n",
      "                                     uniqueprotoname  bestoverhang  Namenr  \\\n",
      "0  NM_000157.4(GBA):c.630del (p.Val211fs)GGGCTGGC...          15.0    1398   \n",
      "1  NM_178152.3(DCX):c.266G>C (p.Arg89Pro)TGATGTTG...          10.0   12847   \n",
      "2  NM_000527.4(LDLR):c.1786A>T (p.Lys596Ter)CGATG...           7.0    4361   \n",
      "3  NM_000135.4(FANCA):c.3558dup (p.Arg1187fs)GCCT...           7.0    1005   \n",
      "4  NM_006920.6(SCN1A):c.3769_3779del (p.Leu1257fs...          10.0    9630   \n",
      "\n",
      "   uniqueindex flapbasebefore_revcomp  flabbaserevised basebeforeproto  chrom  \\\n",
      "0        53958                      A                A               G   chr1   \n",
      "1        44830                      T                T               T   chrX   \n",
      "2        59091                      C                C               T  chr19   \n",
      "3        13498                      G                G               A  chr16   \n",
      "4        80275                      T                T               T   chr2   \n",
      "\n",
      "         pos  \n",
      "0  155238264  \n",
      "1  111410133  \n",
      "2   11116939  \n",
      "3   89745026  \n",
      "4  166012175  \n",
      "\n",
      "[5 rows x 189 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from dataset import parse_hgvs\n",
    "from os.path import join as pjoin\n",
    "import pandas as pd\n",
    "\n",
    "# load the small dataset\n",
    "path = pjoin('data', 'pridict-90k-small.csv')\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "df = parse_hgvs(df)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gene to Strand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   averageedited  averageunedited  averageindel  \\\n",
      "0      17.184357        81.528725      1.286918   \n",
      "1       0.031358        98.626012      1.342630   \n",
      "2      42.450889        49.839235      7.709876   \n",
      "3      45.304817        26.826022     27.869160   \n",
      "4      53.442665        32.004582     14.552753   \n",
      "\n",
      "                                              HGVS      Gene  \\\n",
      "0                        NR_001566.1(TERC):n.79del      TERC   \n",
      "1  NM_016953.4(PDE11A):c.2268_2272del (p.Ser757fs)    PDE11A   \n",
      "2     NM_000488.3(SERPINC1):c.500A>C (p.Asn167Thr)  SERPINC1   \n",
      "3       NM_080679.2(COL11A2):c.109G>T (p.Ala37Ser)   COL11A2   \n",
      "4         NM_000046.5(ARSB):c.454C>T (p.Arg152Trp)      ARSB   \n",
      "\n",
      "                                           Phenotype  PBSlength  \\\n",
      "0          Dyskeratosis congenita autosomal dominant         13   \n",
      "1  Pigmented nodular adrenocortical disease, prim...         13   \n",
      "2                  Reduced antithrombin III activity         13   \n",
      "3  Deafness, autosomal recessive 53;Nonsyndromic ...         13   \n",
      "4         Mucopolysaccharidosis type VI;not provided         13   \n",
      "\n",
      "   RToverhanglength  RTlength ReferenceAllele  ...  \\\n",
      "0                10        24               G  ...   \n",
      "1                 7        18           AGGAC  ...   \n",
      "2                15        27               T  ...   \n",
      "3                 3         5               C  ...   \n",
      "4                10        25               G  ...   \n",
      "\n",
      "                                     uniqueprotoname bestoverhang  Namenr  \\\n",
      "0     NR_001566.1(TERC):n.79delCCCTAACTGAGAAGGGCGT13         15.0   13345   \n",
      "1  NM_016953.4(PDE11A):c.2268_2272del (p.Ser757fs...         10.0   10592   \n",
      "2  NM_000488.3(SERPINC1):c.500A>C (p.Asn167Thr)TT...         15.0    3624   \n",
      "3  NM_080679.2(COL11A2):c.109G>T (p.Ala37Ser)GGAG...         10.0   12122   \n",
      "4  NM_000046.5(ARSB):c.454C>T (p.Arg152Trp)ATGGTC...          7.0     275   \n",
      "\n",
      "   uniqueindex  flapbasebefore_revcomp flabbaserevised  basebeforeproto   chr  \\\n",
      "0        72493                       G               G                A  chr3   \n",
      "1        91023                       C               C                C  chr2   \n",
      "2        60783                       T               T                A  chr1   \n",
      "3        30172                       C               C                G  chr6   \n",
      "4        10383                       C               C                T  chr5   \n",
      "\n",
      "         pos strand  \n",
      "0  169764981      +  \n",
      "1  177697404      -  \n",
      "2  173911923      -  \n",
      "3   33189443      -  \n",
      "4   78969051      +  \n",
      "\n",
      "[5 rows x 190 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from dataset import parse_hgvs\n",
    "from os.path import join as pjoin\n",
    "import pandas as pd\n",
    "from pyensembl import EnsemblRelease\n",
    "\n",
    "ensembls = [EnsemblRelease(111)]\n",
    "\n",
    "# load the small dataset\n",
    "path = pjoin('data', 'pridict-90k-small.csv')\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "# add coordinates of the edit\n",
    "data = parse_hgvs(data)\n",
    "\n",
    "genes = data['Gene'].tolist()\n",
    "strand = []\n",
    "\n",
    "for gene in genes:\n",
    "    i = 0\n",
    "    gene_data = None\n",
    "    while i < len(ensembls):\n",
    "        ensembl = ensembls[i]\n",
    "        try:\n",
    "            gene_data = ensembl.genes_by_name(gene)[0]\n",
    "            # print(\"Gene:\", gene.name)\n",
    "            # print(\"Location:\", gene.contig, gene.start, \"-\", gene.end)\n",
    "            # print(\"Strand:\", \"Forward\" if gene.strand == 1 else \"Reverse\")\n",
    "            break\n",
    "        except:\n",
    "            i += 1\n",
    "    if gene_data is not None:\n",
    "        strand.append(\"Fw\" if gene_data.strand == 1 else \"Rv\")\n",
    "    else:\n",
    "        print(f\"{gene} not found\")\n",
    "        strand.append(None)\n",
    "\n",
    "target_strand = data['Target_Strand'].tolist()\n",
    "# remove the \"'\" from the strand\n",
    "target_strand = [s.replace(\"'\", '') for s in target_strand]\n",
    "\n",
    "# add a strand column to the dataset\n",
    "# if target strand matches the gene strand, it is a sense edit\n",
    "data['strand'] = ['+' if str(s) == str(t) else '-' for s, t in zip(strand, target_strand)]\n",
    "# remove rows where strand is None\n",
    "data = data[[s is not None for s in strand]]\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "# use the forward or reverse of the target strand and the Editing_Position column to identify the gRNA binding region\n",
    "# the 23 bp long regions are marked with start and end columns, inclusive\n",
    "data['start'] = data['pos'] - data['Editing_Position'] - data['PBSlength'] + 1 if strand == 'Fw' else data['pos'] + data['Editing_Position'] + data['PBSlength'] - 22\n",
    "data['end'] = data['start'] + 22\n",
    "\n",
    "data['target_sequence'] = data['wide_initial_target'].str.slice(10, 33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72, 72, 70, 71, 72, 71, 71, 71, 72, 71, 71, 72, 72, 70, 70, 72, 70, 72, 72, 70, 70, 70, 70, 72, 72, 70, 70, 72, 72, 72]\n",
      "Flank sequences generated from GRCh38\n",
      "/home/peiheng/development/pe-off\n",
      "NuPoP occupancy and affinity annotations generated\n",
      "GC content annotation generated\n",
      "Nucleotide BDM annotation generated\n"
     ]
    }
   ],
   "source": [
    "from dataset import convert_pridict_to_crispai\n",
    "from os.path import join as pjoin\n",
    "import pandas as pd\n",
    "\n",
    "# load the small dataset\n",
    "path = pjoin('data', 'pridict-90k-small.csv')\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "data = convert_pridict_to_crispai(data)\n",
    "\n",
    "# save to the data folder\n",
    "data.to_csv(pjoin('data', 'crispai-90k-small.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 out of 30 sgRNAs are in the context sequence\n",
      "0 out of 30 sgRNAs are in the context sequence when considering the complement\n",
      "0 out of 30 sgRNAs are in the context sequence when considering the reverse order\n",
      "0 out of 30 reverse complement sgRNAs are in the context sequence\n",
      "[[72], [72], [72], [72], [72], [72], [72], [72], [72], [72], [72], [72], [72], [72], [72], [72], [72], [72], [72], [72], [72], [72], [72], [72], [72], [72], [72], [72], [72], [72]]\n",
      "1 [72] -\n",
      "2 [72] +\n",
      "3 [72] -\n",
      "4 [72] +\n",
      "5 [72] -\n",
      "6 [72] +\n",
      "7 [72] +\n",
      "8 [72] +\n",
      "9 [72] +\n",
      "10 [72] +\n",
      "11 [72] +\n",
      "12 [72] -\n",
      "13 [72] -\n",
      "14 [72] +\n",
      "15 [72] +\n",
      "16 [72] -\n",
      "17 [72] +\n",
      "18 [72] -\n",
      "19 [72] -\n",
      "20 [72] +\n",
      "21 [72] +\n",
      "22 [72] +\n",
      "23 [72] +\n",
      "24 [72] -\n",
      "25 [72] -\n",
      "26 [72] +\n",
      "27 [72] +\n",
      "28 [72] -\n",
      "29 [72] -\n",
      "30 [72] -\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# make sure sgRNA_sequence is contained in the context sequence flank_73 sequence\n",
    "data = pd.read_csv('data/crispai-90k-small.csv')\n",
    "\n",
    "data['sgRNA_sequence'] = data['sgRNA_sequence'].str.slice(0, 19)\n",
    "\n",
    "sgRNA_in_context = [sgRNA in context for sgRNA, context in zip(data['sgRNA_sequence'], data['context sequence flank_73'])]\n",
    "\n",
    "print(f'{sum(sgRNA_in_context)} out of {len(data)} sgRNAs are in the context sequence')\n",
    "\n",
    "def complement(sequence):\n",
    "    complement = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A'}\n",
    "    return ''.join([complement[base] for base in sequence])\n",
    "\n",
    "# check if the complementary sequence of sgRNA is in context\n",
    "comp_sgRNA_in_context = [complement(sgRNA) in context for sgRNA, context in zip(data['sgRNA_sequence'], data['context sequence flank_73'])]\n",
    "\n",
    "print(f'{sum(comp_sgRNA_in_context)} out of {len(data)} sgRNAs are in the context sequence when considering the complement')\n",
    "\n",
    "# reverse the order of the sgRNA sequence and check if it is in the context sequence\n",
    "sgRNA_inversed_in_context = [sgRNA[::-1] in context for sgRNA, context in zip(data['sgRNA_sequence'], data['context sequence flank_73'])]\n",
    "\n",
    "print(f'{sum(sgRNA_inversed_in_context)} out of {len(data)} sgRNAs are in the context sequence when considering the reverse order')\n",
    "\n",
    "# check the complement of the inverse sgRNA in the context sequence\n",
    "comp_sgRNA_inversed_in_context = [complement(sgRNA[::-1]) in context for sgRNA, context in zip(data['sgRNA_sequence'], data['context sequence flank_73'])]\n",
    "\n",
    "print(f'{sum(comp_sgRNA_inversed_in_context)} out of {len(data)} reverse complement sgRNAs are in the context sequence')\n",
    "\n",
    "import regex\n",
    "\n",
    "def find_all(string, substring):\n",
    "    start = 0\n",
    "    indices = []\n",
    "\n",
    "    while start < len(string):\n",
    "        start = string.find(substring, start)\n",
    "        if start == -1:\n",
    "            break\n",
    "        indices.append(start)\n",
    "        start += 1\n",
    "    \n",
    "    return indices\n",
    "\n",
    "# locate the sgRNA in the context sequence\n",
    "sgRNA_positions = [find_all(context, sgRNA) for sgRNA, context in zip(data['sgRNA_sequence'], data['context sequence flank_73'])]\n",
    "\n",
    "print(sgRNA_positions)\n",
    "\n",
    "# print positions with index\n",
    "for ind, pos in enumerate(sgRNA_positions):\n",
    "    print(ind+1, pos, data.loc[ind, 'strand'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
